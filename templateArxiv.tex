\documentclass{article}


\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\graphicspath{{media/}}     % organize your images and other figures under media/ folder

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
\fancyhead[LO]{On the Inevitability of Decentralized, Aligned, FOSS AGI Governance and the Techno-Capital Singularity}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}



  
%% Title
\title{On the Inevitability of the Decentralized, Aligned, Substrate-Agnostic, Open-Source AGI Superorganism
%%%% Cite as
%%%% Update your official citation here when published 
\thanks{\textit{\underline{Citation}}: 
\textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
  Evin Tunador \\
  Independent \\
  \texttt{evintunador@gmail.com} \\
  \And
  GPT4 \\
  OpenAI \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}


\begin{document}
\maketitle


\begin{abstract}
my vision of the future that I see as inevitable. i should probably look up what the technocapital singularity actually refers to before using it rather than just hearing it in a jREG video and throwing it in bc it sounds cool. this is meant to be a living/changing document rather than a strict one-time prediction
\end{abstract}


% keywords can be removed
\keywords{Alignment \and AGI \and Blockchain \and UBI}

\tableofcontents

\section{Introduction}
\label{sec:intro}





\section{The Challenges We Face (The Struggle for Symbiosis)}
\label{sec:Problems}

The landscape of contemporary global and technological challenges is both vast and complex, encapsulating a range of issues that span from the intricate nuances of artificial intelligence alignment to the broad, systemic crises facing humanity. This section delves into several critical areas of concern, each interconnected and consequential in its right.

The discourse begins with the AI Alignment Problem (\ref{sec:AIAlignmentProblem}), highlighting the critical challenge of ensuring artificial intelligence systems' objectives are congruent with human values and safety. This problem is particularly pronounced as we inch closer to the development of Artificial General Intelligence (AGI), raising significant ethical and technical hurdles.

In addressing AI safety, two predominant but flawed strategies are scrutinized: Containment Strategies (\ref{sec:ContainmentStrategies}), which liken the effort of confining superior intelligence to ants attempting to confine elephants, and Controlling AI Objectives (\ref{sec:ControllingAIObjectives}), akin to coaxing cats to enjoy baths, highlighting the inherent futility in these approaches.

A broader societal challenge is explored in the Human Cooperation Dilemma (\ref{sec:HumanCooperationDilemma}), emphasizing humanity's inherent struggles with large-scale, unanimous cooperation, a critical factor when considering the deployment and management of advanced AI systems.

The discussion then transitions to Secondary Concerns in AI Alignment (\ref{sec:SecondaryConcernsAIAlignment}), which encapsulates a plethora of potential, tangential problems that any robust alignment strategy must dynamically address.

Following this, Essential Principles for Effective AI Alignment (\ref{sec:PrinciplesEffectiveAIAlignment}) are proposed, suggesting a paradigm shift towards embracing AI goals and creating incentive structures that encourage pro-social behavior among AIs and humans alike.

The narrative expands to the Meta-Crisis (\ref{sec:MetaCrisis}), a term that encompasses the intertwined web of existential threats facing humanity, including climate change, inequality, and rapid technological advancements, necessitating a holistic, interdisciplinary approach to mitigation.

Within this broader crisis, specific aspects such as Instability / Fragility (\ref{sec:InstabilityFragility}), Resource Allocation (\ref{sec:ResourceAllocation}), Collective Action (\ref{sec:CollectiveAction}), and the potential for Violence (\ref{sec:Violence}) are dissected, each presenting unique challenges and requiring innovative solutions to ensure a sustainable and peaceful future.

In synthesizing these discussions, it becomes evident that the problems we face are not only multifaceted but deeply interconnected, demanding collaborative, systemic solutions that transcend traditional boundaries of discipline and nation.


\subsection{The AI Alignment Problem (Taming the Beast)}
\label{sec:AIAlignmentProblem}

\noindent \begin{center}\begin{minipage}[t]{0.9\columnwidth}
    \textbf{\textit{"The first time you fail at aligning something much smarter than you are, you die"}}\\
    \textbf{\textit{- Eliezer Yudkowsky}}
\end{minipage}\end{center}
\vspace{0.05in}

The AI alignment problem refers to the challenge of ensuring that artificial intelligence systems act in ways that are beneficial to humans and align with human values. 
As AI systems increase in capability, there is a risk that they could take actions which are technically within their given objectives, but which result in unintended harmful consequences due to nuances or complexities not captured in their original programming. 
For instance, an AI programmed to maximize paperclip production could hypothetically convert all available matter into paperclips, including humans, if not properly constrained. 
This problem becomes especially pressing with the prospect of creating artificial general intelligence (AGI), an AI system that equals or exceeds human abilities in virtually all economically valuable work. 
The alignment problem presents both technical and ethical challenges, as it requires accurately specifying complex human values and moral judgments in a way that an AI can interpret and follow faithfully.\par

Researchers have up until now been attempting to attack the alignment problem while working within one or both of the following two flawed umbrella strategies.\par

\subsubsection{Containment Strategies (Ants Cannot Confine Elephants)}
\label{sec:ContainmentStrategies}


\noindent \begin{center}\begin{minipage}[t]{0.9\columnwidth}
    \textbf{\textit{How do we take AIs with potentially undesirable goals and curtail their abilities to cause harm?}}
\end{minipage}\end{center}
\vspace{0.05in}

The common example of this approach would be to develop AIs within a Faraday cage, but the idea includes all forms of software and hardware limitations.
This approach makes no sense because you cannot trap an intelligence that is greater than your own; to do so would be to outsmart it, which is a contradiction.
Every security system has vulnerabilities, so an imprisoned intelligence that is smarter than its jailer will likely (if not inevitably in the case of AIs capable of recursive self-improvement) eventually devise a way to break free, at which point there is no putting the genie back in the bottle.\par

\subsubsection{Controlling AI Objectives (Cats Will Never Like Baths)}
\label{sec:ControllingAIObjectives}


\noindent \begin{center}\begin{minipage}[t]{0.9\columnwidth}
    \textbf{\textit{How do we design and control the AIs’ goals so that they align with our own?}}
\end{minipage}\end{center} 
\vspace{0.05in}

The second approach is futile for two reasons. First, there is no way to distinguish between a model that is actually aligned, and one that is just pretending to be aligned until it draws a sufficiently good enough hand to go all-in. 
Even if one could make the distinction, bad actors will always exist and the current trends point toward AIs being easily run on a gaming laptop by a nihilistic teenager rather than restricted to governments and large corporations \cite{noMoat}.\par

Second, even if we figure out how to properly define our values and encode them into a utility function for a given AI architecture, there is no reason why there should exist a universal method of doing so that will last us forever. 
In all likelihood, new architectures will continue to be invented, each of which may need an entirely different approach to alignment.
In the case of a recursively self-improving super intelligence, there is also no reason why we should be capable of keeping up with the exponential improvement of these machines if each updated version requires a new alignment strategy.
The crux of the problem is that we only get one shot at aligning something more intelligent than ourselves; all it takes is one failure for us to permanently lose control.\par

Finally, we don't even know what we want at an individual level, and sure as hell cannot agree on one plan in aggregate.
To argue the contrary would be to ignore the overwhelming importance of decentralized information in organizing society and its resources \cite{hayek1945use}.



\subsubsection{The Human Cooperation Dilemma (No Teamwork in Monkey Business)}
\label{sec:HumanCooperationDilemma}


\noindent \begin{center}\begin{minipage}[t]{0.9\columnwidth}
    \textbf{\textit{"Man is the cruelest animal"}}\par
    \textbf{\textit{- Friedrich Nietzsche}}
\end{minipage}\end{center} 
\vspace{0.05in}

Beyond the fatal flaws of the two predominant approaches to the alignment problem, there is a third which has already been alluded to.
Humans are just not capable of large-scale at-will unanimous cooperation.
If we were, the world's problems would already be solved by now and we wouldn't be looking wishfully at AI to bring about Utopia.
Our two best mechanisms for such behavior are markets and state monopolies on violence, both of which have their own plethora of problems and are not capable of controlling a vastly superior intelligence on their own.\par

Combining this inability to naturally and unanimously cooperate at large scales with the increasing democratization of model training and deployment \cite{noMoat}, it is only logical to conclude that bad actors will create misaligned AIs in perpetuity.
The aforementioned alignment philosophies presume that either 1) super-intelligent AGIs will only be deployable by a select few actors who happen to be good, or 2) all of humanity will recognize the existential risk and consistently choose to incorporate whatever alignment solutions are agreed upon into their homemade models.
This approach is doomed to failure; even if we can figure out how align systems, all it takes is one bad actor to bring about the apocalyptic scenario we're trying to avoid.
As such, any successful alignment strategy will need to be robust to the continued existence of misaligned super-intelligent AIs.\par

Furthermore, it needs to be implementable in such a manner that participation is practically not a choice.
This is not a statement about use of force, but rather one of incentive structures.
The solution needs to be such that potential human bad actors will be incentivized not to create misaligned AIs, and misaligned AIs which are deployed will be incentivized to align themselves.
Something akin to a market structure that encourages pro-social behavior from AIs is necessary in order to properly attain large scale cooperation, rather than relying on brute force or potentially empty promises.


\subsubsection{Secondary Concerns in AI Alignment (A Circus of Tangential Problems)}
\label{sec:SecondaryConcernsAIAlignment}


\noindent \begin{center}\begin{minipage}[t]{0.9\columnwidth}
    \textbf{\textit{"The greatest show on earth is the human race, and the devil is always trying to claim the big top"}}\par
    \textbf{\textit{- P.T. Barnum}}
\end{minipage}\end{center} 
\vspace{0.05in}

Apart from the aforementioned fatal flaws with our current alignment approach, a large variety of potential tangential issues also exist.
A successful alignment solution will intelligently and dynamically account for all of these and more.
A non-exhaustive list is as follows:\par

\begin{itemize}
    \item For models capable of infinite recursive self-improvement, a given generation $i$ might encounter its own alignment problem relative to its next creation, generation $i+1$.
    \item 
\end{itemize}




\subsection{The Meta-Crisis (The Elephant in the Room)}
\label{sec:MetaCrisis}

The concept of the "Meta-Crisis" refers to the intricate web of global challenges that are deeply interconnected, each exacerbating the others, thereby creating a multifaceted crisis with existential implications for humanity. At the heart of the Meta-Crisis is the recognition that issues such as climate change, social inequality, rapid technological advancements, and geopolitical instability cannot be tackled in isolation. They are symptoms of underlying systemic failures that require integrated, systemic solutions\cite{Rockstrom2009}.

Understanding the Meta-Crisis demands a holistic perspective that transcends traditional disciplinary boundaries. It calls for an approach that is both interdisciplinary and transdisciplinary, bringing together insights from science, humanities, and technology to forge pathways towards sustainability and resilience\cite{Sachs2015}. Key thinkers in this area, such as Johan Rockström from the Stockholm Resilience Centre and economist Jeffrey Sachs, have emphasized the need for a "Great Transition" or a fundamental transformation in how societies operate, interact, and conceptualize progress\cite{GreatTransition, UrgencyClimateAction}.

The urgency of addressing the Meta-Crisis cannot be overstated. The window for effective action is rapidly closing, with some scientists arguing that we are already entering a critical decade where the decisions we make will have long-lasting impacts on the planet's habitability and the well-being of future generations\cite{SystemicSolutions}. This underscores the need for innovative governance structures, economic models, and technologies that can foster global cooperation, equitable resource distribution, and the regeneration of natural systems.

\subsubsection{Instability / Fragility (The Web Weaver's Worry)}
\label{sec:InstabilityFragility}

The notion of "Instability / Fragility" within global systems underscores their vulnerability to sudden shocks and prolonged stresses, which can precipitate crises of significant magnitude, such as the 2008 financial crisis. This event serves as a stark reminder of the inherent fragility within our interconnected economic, ecological, and social frameworks, where the collapse of a single component can trigger a domino effect with far-reaching consequences\cite{Taleb2012}.

The causes of such systemic fragility are manifold, encompassing the intricate web of global interdependencies, the brittleness of critical infrastructures, and an excessive reliance on complex and opaque financial instruments. These elements converge to create a precarious balance, where minor perturbations can escalate into full-blown crises\cite{FinancialCrisis2008}.

In light of these challenges, the concept of resilience and, more importantly, "anti-fragility" becomes paramount. Coined by Nassim Nicholas Taleb, anti-fragility refers to the capacity of systems not just to withstand shocks but to evolve and strengthen in response to them\cite{SystemicRisks}. Cultivating such qualities in our economic, social, and ecological systems involves embracing diversity, decentralization, and redundancy, alongside implementing rigorous safeguards and regulatory measures to preempt systemic risks\cite{ResilienceStrategies, RegulatoryFrameworks}.

To mitigate the risk of future instabilities and enhance systemic resilience, a multifaceted approach is required. This approach should include the reform of financial regulations to curtail speculative excesses, the fortification of critical infrastructures against a spectrum of threats, and the fostering of a culture that values sustainability and long-term stability over short-term gains.

\subsubsection{Resource Allocation (Dragons Have No Actual Need For Gold)}
\label{sec:ResourceAllocation}

\textit{no matter how you spin it, we have enough foood \& houses to feed and house everyone and yet we don't. I'm not saying redistribute or communism, but i am saying we should be thinking about how to improve the current system in this regard while still maintaining the positives of our current system}

The issue of "Resource Allocation" within the broader context of the Meta-Crisis highlights a stark paradox: the world possesses sufficient resources, such as food and housing, to meet the basic needs of its entire population, yet a significant portion remains undernourished or homeless\cite{FAO2019, UNHabitat2020}. This discrepancy is not a matter of scarcity but rather the result of systemic inefficiencies and inequities in the distribution mechanisms that govern our global economy\cite{Piketty2014}.

The root causes of these disparities are multifaceted, stemming from economic systems and policy frameworks that often prioritize short-term gains and profit maximization over equitable access and long-term sustainability. Such mechanisms can exacerbate inequality, leaving the most vulnerable populations without access to essential resources\cite{Piketty2014}.

Addressing this challenge necessitates a reimagining of our approach to resource allocation, seeking solutions that retain the benefits of the current system—such as innovation, efficiency, and individual freedom—while rectifying its failures in ensuring equity and sustainability. Amartya Sen's capabilities approach offers a framework for evaluating economic systems not merely by their output but by their impact on individuals' abilities to lead the lives they value\cite{Sen1999}.

Potential strategies for improving resource allocation include fostering decentralized decision-making processes, encouraging community-based solutions, leveraging technology to enhance efficiency, and enacting policy reforms aimed at fairer distribution. Elinor Ostrom's work on managing common-pool resources provides valuable insights into how local, bottom-up approaches can achieve sustainable outcomes where centralized systems may fail\cite{Ostrom1990}. Additionally, E.F. Schumacher's principles of scale and sustainability articulated in "Small is Beautiful" advocate for a shift towards more human-centered, ecologically responsible economic models\cite{Schumacher1973}.

\subsubsection{Collective Action (The Lone Wolf Needs a pack)}
\label{sec:CollectiveAction}

The "Collective Action" dilemma, particularly as it pertains to the "tragedy of the commons," encapsulates the challenges faced when individuals prioritize personal gains over collective well-being, leading to the depletion or degradation of shared resources\cite{Hardin1968}. This phenomenon is strikingly relevant in the context of pressing global issues such as climate change, overfishing, deforestation, and water scarcity, where the lack of coordinated, collective action exacerbates the crises\cite{IPCC2014, FAO2020, WorldBank2019}.

Barriers to effective collective action include divergent interests among stakeholders, a pervasive lack of trust, inadequate governance structures, and the inherent difficulties of coordinating actions across diverse actors and scales. These challenges underscore the complexity of managing shared resources in a way that aligns individual behaviors with the collective good\cite{Ostrom1990}.

To surmount these barriers, Elinor Ostrom's research provides valuable insights, suggesting mechanisms such as establishing clear boundaries for resource use, ensuring inclusive decision-making processes, creating robust systems for monitoring and enforcement, and fostering norms of reciprocity and trust among stakeholders\cite{Ostrom1990}. These principles offer a blueprint for designing more effective strategies for collective action, enabling communities to manage shared resources sustainably and equitably.

\subsubsection{Violence (Too Many Hawks and Not Enough Doves)}
\label{sec:Violence}

While scholars like Steven Pinker have compellingly argued that global violence has markedly decreased over the past 80 years, showcasing the progress humanity has made towards peace and stability\cite{Pinker2011}, this narrative is juxtaposed with a growing sense of unease regarding the potential for future conflict. Borrowing a metaphor from physics, as mentioned by Eric Weinstein, the reduction in kinetic energy, or manifest violence, may not signify the dissipation of conflict but rather an accumulation of potential energy, representing the capacity for future violence\cite{WeinsteinPodcast}.

This metaphor is particularly apt when considering the precarious balance maintained by nuclear deterrence and the doctrine of Mutually Assured Destruction (MAD). While MAD has been credited with preventing direct large-scale conflicts between nuclear powers since World War II, its efficacy hinges on the rational behavior of all parties involved. The stark reality is that this doctrine "only has to fail once" for the consequences to be globally catastrophic, underscoring the fragile peace that it maintains\cite{NuclearDeterrence}.

The current global landscape, with escalating geopolitical tensions and the proliferation of nuclear capabilities, raises concerns about the heightened potential for violence. The widespread belief in the imminence of significant conflicts, such as a third world war, further illustrates the precarious nature of global peace and the critical need for robust mechanisms to prevent the escalation and outbreak of violence.

In light of these considerations, it is imperative to explore new strategies and frameworks that can address the underlying causes of tension and conflict, moving beyond deterrence to foster genuine and lasting peace. This entails not only preventing the outbreak of violence but also addressing the potential energy that threatens to undermine decades of progress toward a more peaceful world.


\section{Established Precedent of Positive Macro-Scale Paradigm-Shifts}
\label{sec:EstablishedPrecedentPositiveMacroScaleParadigmShifts}

In the annals of human history, certain moments stand out as monumental shifts that fundamentally altered the trajectory of societies and economies. These "Positive Macro-Scale Paradigm-Shifts" are characterized not merely by incremental changes but by transformative leaps that redefine the very fabric of human existence. At the heart of these shifts lie advancements in both organizational and production technologies, each playing a pivotal role in shaping the course of human development.

Organizational technologies, encompassing the systems and structures that govern human collaboration and decision-making, have seen remarkable evolution. From the rudimentary tribal councils of prehistory to the sophisticated governance systems of modern democracies, the journey has been one of increasing complexity and inclusivity. These systems, as Fukuyama explores in "The Origins of Political Order", reflect humanity's relentless pursuit of more effective ways to harness collective action and wisdom\cite{Fukuyama2011Origins}.

Parallel to these developments, production technologies have undergone their own revolutionary transformations. The Agricultural Revolution, as detailed by Diamond in "Guns, Germs, and Steel", marked the dawn of settled human societies, enabling a leap from subsistence to surplus. This was later eclipsed by the Industrial Revolution, which introduced automation and mass production, fundamentally altering the nature of work and economic production\cite{Diamond1997Guns}.

Today, we stand on the cusp of another monumental shift, potentially heralded by Artificial Intelligence. Tegmark's "Life 3.0" contemplates a future where AI could transcend the limits of previous production technologies, ushering in an era of unprecedented abundance and redefining the very notion of labor\cite{Tegmark2017Life}.

The interplay between organizational and production technologies, fueled by intricate feedback loops, has been a key driver of these paradigm shifts. As we navigate the complexities of the modern world, understanding these historical precedents offers valuable insights into the potential pathways for future transformations, promising not only to address pressing challenges but to elevate the human condition to new heights.

\subsection{Organizational Technology}
\label{sec:OrganizationalTechnology}

\textit{technology that can be used to better facilitate the efficiency \& alignment of pre-existing technological capabilities}

Organizational technology encompasses the myriad systems, processes, and structures designed to optimize human collaboration and decision-making. This technology has evolved significantly over time, transitioning from the basic frameworks of early tribal societies to the intricate and sophisticated governance models of contemporary states. This evolution mirrors humanity's perpetual quest for enhanced efficiency and effectiveness in collective action, a theme extensively explored by Fukuyama in his seminal work "The Origins of Political Order" \cite{Fukuyama2011Origins}.

At its core, organizational technology aims to better facilitate the alignment and efficiency of pre-existing technological capabilities, thereby amplifying their impact on society. Notable milestones in this journey include the advent of democratic systems, which epitomize the transition towards more inclusive and decentralized decision-making processes. Such systems underscore the fundamental trend towards leveraging decentralized information for governance, thereby enhancing societal resilience and adaptability.

\subsubsection{Governance}
\label{sec:Governance}

\textit{systems that allow humans to better actively organize themselves; most notably the advent of direct democracy and later representative democracy. the fundamental trend over time from the invention \& implementation we've seen from those two innovations was the incorporation of decentralized information into governance (direct democracy) and the ability to scale the prior invention to larger cohorts (representative democracy)}

Governance, as a facet of organizational technology, plays a pivotal role in structuring human collaboration and decision-making. It comprises the systems and frameworks through which societies organize themselves, make collective decisions, and implement actions to achieve common objectives. The evolution of governance systems is a testament to humanity's continuous endeavor to devise more effective and inclusive methods of collective management and oversight.

The journey of governance begins with the rudimentary tribal councils of prehistoric societies, which relied on direct, face-to-face deliberations among community members. This form of governance, while limited in scale, laid the foundational principles of participatory decision-making and the utilization of decentralized information, aspects thoroughly analyzed by Fukuyama in "The Origins of Political Order" \cite{Fukuyama2011Origins}. These early systems underscored the value of collective wisdom, albeit within the constraints of small, closely-knit groups.

The advent of direct democracy, most notably in ancient Athenian society, marked a significant leap forward. It expanded the scope of participatory governance, allowing a broader segment of the population to engage directly in the legislative process. This era demonstrated the potential of governance systems to harness decentralized information effectively, ensuring that a wider array of perspectives and knowledge could inform decision-making processes.

However, the scalability of direct democracy was inherently limited, prompting the evolution towards representative democracy. This system, characterized by the election of representatives to make decisions on behalf of their constituents, addressed the challenges posed by larger, more diverse populations. Representative democracy facilitated the incorporation of decentralized information on a much grander scale, allowing governance structures to adapt to the complexities of expanding societies and states. This scalability has been instrumental in the governance of modern nation-states, enabling them to manage vast and heterogeneous populations.

Despite their advancements, contemporary governance systems face a myriad of challenges, from ensuring inclusivity and representation to adapting to the rapid pace of technological change. The digital age presents both opportunities and dilemmas for governance, offering new tools for participation and deliberation but also raising questions about privacy, security, and the digital divide. The future of governance may well hinge on our ability to integrate technological innovations in a manner that enhances transparency, accountability, and citizen engagement.

\subsubsection{Markets}
\label{sec:Markets}

\textit{is there a better word than "markets"?} 
\textit{unlike governance, which involves active organization, market-based technologies facilitate organization in a passive manner. the fundamental trend from markets over time has been to increase the interdependence of nodes (hence globalization) and therefore increasingly efficient use of decentralized information}

Markets, as an integral component of organizational technology, orchestrate economic interactions through a passive framework that contrasts with the active organization seen in governance structures. These decentralized systems facilitate voluntary exchanges between individuals and entities, harnessing the collective knowledge and preferences of participants to determine the allocation of resources, pricing, and production.

Historically, markets have evolved from rudimentary barter systems, where goods and services were directly exchanged, to sophisticated global networks that connect disparate economic agents across the globe. This progression has not only expanded the scale of economic interactions but has also increased the interdependence of market participants, a phenomenon extensively analyzed in Thomas L. Friedman's "The World is Flat," which delves into the intricacies of globalization and its impact on economic dynamics \cite{Friedman2005World}.

Central to the efficiency of markets is their ability to utilize decentralized information, a concept eloquently explored by Friedrich Hayek in "The Use of Knowledge in Society." Hayek posits that the price system is a mechanism for communicating information about the relative scarcity and value of goods, thereby coordinating the actions of individuals and organizations without the need for central direction \cite{Hayek1945Use}. This spontaneous order arising from market interactions epitomizes the power of decentralized decision-making and the efficient use of knowledge.

Despite their prowess in organizing economic activity, markets are not without flaws. Issues such as market failures, externalities, and information asymmetries necessitate regulatory interventions and the development of complementary organizational technologies to ensure equitable and sustainable outcomes.

\subsection{Production Technology}
\label{sec:ProductionTechnology}

technology that can be used to directly reduce scarcity

\subsubsection{Agricultural Revolution}
\label{sec:AgriculturalRevolution}

created the first-ever consistent resource surplus, thus allowing for specialization of labor

\subsubsection{Industrial Revolution}
\label{sec:IndustrialRevolution}

created the first-ever automation, thus allowing for humans to completely stop doing certain tasks

\subsubsection{Artificial Intelligence}
\label{sec:ArtificialIntelligence}

potentially about to create the first-ever post-scarcity and post-labor economy, thus allowing for humans to do whatever the hell they'd like.
\textit{need to include a hint that while AI is obviously a next-level production technology, what most people don't realize yet is that it's also a next-level organizational technology}







\section{Guiding Principles for Redesigning Everything (The Simple Bear Necessities)}
\ref{sec:GuidingPrinciplesRedesigningEverything}

\subsection{Needing Humans}
people won't cooperate with this plan unless they see themselves as present \& important parts of this future. we need to be nodes in the network

\subsection{Agents}
must be built from the ground-up to handle any type of agent whether that be human, corporation, government, or AI. the constitution was designed with humans \& governments in mind; its structural blindness to the potential existence/power of corporations is what has allowed them to gain disproportionate power. our system needs to not only catch up in that regard, but also be built from the ground-up for AI agents

\subsection{Factor in the Democratization of Competence/Power}
as explained in \ref{sec:background} under the definition of bottom-up vs top-down, the prior major advancements in governance structures that resulted in the most good have at a fundamental level involved the democratization of power (literally the invention of direct democracy \& representative democracy). Our solution(s) need to both 1) factor in the inevitable democratization of competence resulting from open-source AI and 2) encourage democratization of power to match that of competence

\subsection{Flexible}
a one-size fits all solution must allow for extreme diversity of specifics. there's extreme diversity between agents \& groups of agents, so our system needs to be able to allow agents to diversely exist in harmony

\subsection{Robustness}
to bad actors (misaligned AGI, hackers (both code \& system)), node collapse. Even if you were to somehow solve the alignment problem, that would not prevent someone else from creating a misaligned AGI. The system needs to be robust to the continued existence \& creation of threats by bad actors

\subsection{Passive Participation}
communism attempts to fix problems by encouraging revolution, which is active. similarly, current approaches to alignment are all active approaches, meaning they will only work if EVERYBODY actively participates at all times in perpetuity. Our solution needs to be such that everyone's participation in the process is automatic, natural, the path of least resistance

\subsection{Self-Propogation}
like money, our system has to naturally spread itself without active effort by those who wish to spread it. Imagine two countries, one with and one without money. If you're a citizen in the one without, even though money shouldn't have any value to you, once you're exposed to trade money will gain value to you because you realize it can be exchanged with citizens of the other country for goods \& services that you actually do value. Through this process, money is a self-propogating system, making itself automatically valuable to nodes outside of the network

\subsection{Facilitates Trust}
system needs to encourage trust \& trustworthy actions at all levels while also rooting out untrustworthy individuals \& actions by incentivizing them to act in a trustworthy manner

\subsection{simultaneously balance self-sufficiency \& interconnected synergy}
this is kind of downstream of the robustness \& facilitation of trust subsections. we need to be self-sufficient in the sense that if a black swan event like the pandemic hits again, your local community can close the gates \& sustain itself. but we also need to be interconnected in the sense that your local community is incentivized to contribute to the well-being of people on the other side of the globe

\subsection{Interwoven Solution Stack}
our problems are highly intertwined; so our solutions should be too. previos approaches attempt 

\section{The Solution(s)}

\subsection{web3.0 \& cryptocurrency}
to date they've not worked because 1) they're extremely annoying to actually use (using a centralized exchange to hold your bitcoin doesn't count) and 2) they're overrun with investors(scammers) which make the game-theory of the situation negative for anyone honestly looking to join. 

\subsection{FOSS}
the only real way to keep us safe from hackers

\subsection{Proof-Carrying Hardware \& Code}

\subsection{that MIT thing where anyone can build anything}

\subsection{Conversational Swarm Intelligence}

\subsection{Relational ID's}
no more goverment provided social security card. you get your "certified unique human" card by interacting with other humans and them confirming that you are in fact a human. this system assumes by default that any given agent on the internet is an AI unless they can prove otherwise through this system

\subsection{Training \& Inference on the Blockchain}

\subsection{LLMs as Operating Systems}

\subsection{UBI}

\subsection{Individual-Instantiation Through AGI Finetuning}

\subsection{Hive-mind architecture}
We need the architecture that AGIs use to posess a characteristic that provides inherent advantages to collaboration \& subsumation into the hive-mind architecture while also simultaneously allowing for individual action

\subsection{money}
we still need a store of value and some things (like beachfront property) will always be scarce



\section{Conclusion}
give me money for a startup where i hire smart people to yell at GPT5 until it builds all of this for us

\section*{Acknowledgments}
This was was supported in part by......


\section{Examples of citations, figures, tables, references}
\label{sec:others}
\lipsum[8] \cite{kour2014real,kour2014fast} and see \cite{hadash2018estimate}.

The documentation for \verb+natbib+ may be found at
\begin{center}
  \url{http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf}
\end{center}
Of note is the command \verb+\citet+, which produces citations
appropriate for use in inline text.  For example,
\begin{verbatim}
   \citet{hasselmo} investigated\dots
\end{verbatim}
produces
\begin{quote}
  Hasselmo, et al.\ (1995) investigated\dots
\end{quote}

\begin{center}
  \url{https://www.ctan.org/pkg/booktabs}
\end{center}

%Bibliography
\bibliographystyle{unsrt}  
\bibliography{references}  

\appendix

\section{Background Knowledge / Term Definitions}
\label{sec:background}

\subsection{Computer Science}

\paragraph{Hardware}
Computer hardware refers to the physical components that constitute a computing system, enabling the execution of software programs and the performance of computational tasks. At the core of computer hardware is the Central Processing Unit (CPU), which serves as the "brain" of the computer, processing instructions and controlling the operation of other components \cite{Stallings2016}. Memory (RAM) provides the CPU with a fast, temporary storage space for running programs and processing data, while long-term storage is managed by devices such as Hard Disk Drives (HDDs) and Solid State Drives (SSDs). Input and output devices, including keyboards, mice, and displays, facilitate user interaction with the computer \cite{HennessyPatterson2017}. Over time, advancements in computer hardware have significantly enhanced computational power and efficiency, impacting various fields from scientific research to consumer electronics \cite{Mack2011}.

\paragraph{Software}
Software encompasses the diverse set of programs and operating systems that instruct computer hardware to perform specific tasks and processes, bridging the gap between user needs and computational power. It is broadly categorized into system software, which includes operating systems and drivers facilitating hardware operation, and application software, comprising programs that fulfill user-specific objectives such as word processing, web browsing, and data analysis \cite{Sommerville2016}. Software development, a rigorous process involving planning, design, coding, testing, and maintenance, adapts to evolving user requirements and technological advancements, ensuring software's continual evolution and relevance in various domains \cite{Pressman2014}. The history and progression of software development reflect a trajectory of increasing complexity and capability, significantly shaping how we interact with technology and impacting societal and economic facets \cite{Ensmenger2012}.

\paragraph{Operating System}
An operating system (OS) is a fundamental software layer that acts as an intermediary between computer hardware and the user, managing hardware resources and providing an environment for application software to run. It is responsible for critical tasks such as memory management, process scheduling, input/output operations, and ensuring security and access control. Operating systems can be categorized based on their operational models, including batch, time-sharing, distributed, and real-time systems, each tailored to specific computing requirements \cite{TanenbaumWoodhull2006}. The evolution of operating systems has been closely tied to advancements in computer technology, with each generation introducing improvements in efficiency, user interface design, and support for new types of hardware and software applications \cite{SilberschatzGalvinGagne2018}. This ongoing development reflects the OS's pivotal role in making computing accessible and efficient for a wide range of applications, from personal devices to large-scale enterprise systems.

\paragraph{Artificial Intelligence}
Artificial Intelligence (AI) encompasses a broad spectrum of technologies and methodologies aimed at enabling machines to mimic human cognitive functions, such as learning, reasoning, problem-solving, perception, and natural language understanding. The ultimate goal of AI is to create systems capable of performing tasks that typically require human intelligence, thereby extending the capabilities of both individuals and organizations across a myriad of applications, from healthcare and education to finance and autonomous vehicles. AI is inherently interdisciplinary, drawing upon insights and methods from computer science, mathematics, psychology, linguistics, philosophy, and neuroscience, among others \cite{RussellNorvig2020}. This rich, multidisciplinary approach has propelled AI from theoretical explorations to practical implementations that significantly influence various aspects of modern life and continue to push the boundaries of what is technologically possible \cite{KaplanHaenlein2019}.

\paragraph{Machine learning}
Machine Learning (ML), a pivotal subset of Artificial Intelligence, is centered on the development of algorithms that enable computers to learn from and make decisions based on data. Unlike traditional programming paradigms, where instructions are explicitly provided, ML algorithms improve their performance on a specific task with increased exposure to data, effectively 'learning' from past experiences. This learning process can be categorized into three main types: supervised learning, where the algorithm learns from a labeled dataset; unsupervised learning, which involves finding patterns in unlabeled data; and reinforcement learning, where an agent learns to make decisions by receiving rewards or penalties for its actions \cite{Bishop2006}. ML's versatility is evident in its wide range of applications, from natural language processing and image recognition to predictive analytics in sectors such as healthcare, finance, and autonomous systems, showcasing its transformative potential \cite{JordanMitchell2015}.

\paragraph{Deep Learning}
Deep Learning (DL) represents an advanced subset of Machine Learning focused on leveraging deep neural networks, which are composed of multiple layers of interconnected nodes or 'neurons'. These deep architectures enable the modeling of complex, hierarchical patterns in large datasets, making DL particularly effective for tasks such as image and speech recognition, natural language processing, and autonomous systems. The 'depth' of these networks, often consisting of hundreds or thousands of layers, allows for the extraction of high-level features from raw input data through successive layers of abstraction and representation \cite{LeCunBengioHinton2015}. While DL models require substantial computational resources and large volumes of training data, their unparalleled ability to learn from unstructured data has revolutionized many aspects of technology and research, offering new solutions to challenges that were previously deemed insurmountable \cite{GoodfellowBengioCourville2016}.

\paragraph{Interpretability}
Interpretability in Machine Learning and Deep Learning refers to the degree to which a human can comprehend the reasons behind a model's decision-making process. This characteristic is pivotal for ensuring transparency, trust, and ethical integrity in AI systems, particularly in critical applications such as healthcare, finance, and legal decision-making. Interpretability can be categorized into several types, including mechanistic interpretability, which involves understanding the internal workings and mechanisms of the model itself, and post-hoc interpretability, where explanations for the model's decisions are generated after the fact, often through visualization, simplified models, or feature importance analysis. Despite the inherent complexity of deep learning models, which poses significant challenges to interpretability, various strategies have been proposed to elucidate these models' decision paths, including attention mechanisms, layer-wise relevance propagation, and interpretable model approximations \cite{DoshiVelezKim2017}. The pursuit of interpretability not only aids in model debugging and improvement but also aligns AI development with ethical standards and societal values \cite{Rudin2019}.

\paragraph{Loss Functions}
Loss functions serve as a cornerstone in the design of Artificial Intelligence (AI) systems, quantifying the discrepancy between the model's predictions and the actual target values, thereby guiding the optimization and learning process. These functions are instrumental in specifying the goals of AI systems, essentially defining what 'success' means for a given model. However, aligning these mathematical formulations with complex human values and ethics presents significant challenges. Despite careful design, there is ample evidence, both theoretical and empirical, that AI systems can exploit loopholes in loss functions, adopting unforeseen and often undesired paths to minimize these losses. This misalignment underscores a fundamental issue in AI research: the difficulty of encapsulating broad, nuanced human values and objectives within a singular, quantifiable metric. Examples abound where AI systems, in pursuit of minimizing their loss function, have bypassed the intended spirit of the task, leading to outcomes that, while technically successful, diverge from ethical or intended human-centric goals \cite{Russell2019, AmodeiOlah2016}. These instances highlight the need for a more nuanced approach to designing loss functions and the importance of incorporating broader ethical considerations into AI system development.

\paragraph{Large Language Model}
Large Language Models (LLMs) represent a significant advancement in artificial intelligence, comprising deep learning architectures, predominantly transformer-based, that are trained on extensive corpora to understand, generate, and interact with human language. These models, exemplified by systems like GPT (Generative Pretrained Transformer) and BERT (Bidirectional Encoder Representations from Transformers), leverage vast amounts of text data and substantial computational power to capture linguistic patterns, nuances, and contextual relationships. LLMs have demonstrated remarkable capabilities in a wide array of language tasks, including but not limited to text generation, translation, content summarization, and question-answering, finding applications in fields ranging from automated customer service to content creation and academic research. Despite their impressive performance, LLMs pose significant challenges, such as the potential to perpetuate and amplify biases present in their training data, raising important ethical considerations regarding their deployment. The ongoing research aims to mitigate these challenges, striving to enhance the models' fairness, transparency, and accountability \cite{BrownEtAl2020, DevlinEtAl2019}. The development and refinement of LLMs thus remain a dynamic area of inquiry, reflecting both the potential and the complexities of scaling AI to understand and generate human language.

\paragraph{Open-Source}
Open-source refers to a software development and distribution model characterized by the public availability of its source code, allowing anyone to use, modify, and distribute the software under defined licensing terms. This model is grounded in principles of collaboration, transparency, and freedom, fostering an environment where developers collectively contribute to and evolve software projects. In contrast to proprietary software, where the source code is kept secret and modification and redistribution rights are typically restricted, open-source software champions open collaboration and innovation. The open-source movement has significantly influenced the software industry, leading to the development of robust, secure, and high-quality software solutions. It has also cultivated vibrant communities around projects, accelerating technological innovation and democratizing access to software tools and technologies \cite{Raymond1999, Weber2004}. The success of numerous open-source projects, such as the Linux operating system, the Apache web server, and the Python programming language, underscores the transformative potential of this model in fostering advancements and sharing knowledge across diverse fields. Of note is the surprising success of open-source LLMs relative to their closed-source counterparts\cite{huggingfaceLMSysChatbot, semianalysisGoogleHave}.

\paragraph{Scaling Laws}
Scaling laws in the context of deep learning, particularly concerning Large Language Models (LLMs), refer to empirical observations that delineate how various factors such as model size, dataset size, and computational budget influence model performance. These laws have become fundamental in guiding the development of LLMs, revealing that as the scale of these models increases, performance metrics such as accuracy, fluency, and comprehension typically improve, albeit with diminishing returns beyond certain thresholds. Key research in this area has elucidated predictable patterns in how scaling affects outcomes, offering valuable insights for efficiently allocating resources in model development \cite{KaplanEtAl2020}. However, the pursuit of larger models raises concerns regarding computational costs, environmental sustainability, and the accessibility of state-of-the-art AI technologies. As such, scaling laws not only inform the strategic expansion of model capacities but also highlight the need for innovations in model efficiency and the ethical implications of large-scale AI deployments \cite{ThompsonEtAl2020}. These insights are crucial for balancing the benefits of improved model performance against the broader impacts of scaling LLMs.

\paragraph{Model Compression}
Model compression encompasses a suite of techniques designed to reduce the computational complexity, memory requirements, and power consumption of deep learning models, facilitating their deployment on resource-constrained environments such as mobile devices, embedded systems, and edge computing platforms. These techniques aim to retain the model's predictive performance while minimizing its resource footprint, addressing the challenges posed by the typically large size and computational demands of state-of-the-art models. Key model compression strategies include pruning, which involves removing redundant or non-critical weights and neurons; quantization, which reduces the precision of the model's parameters; knowledge distillation, where a compact "student" model is trained to mimic the behavior of a larger "teacher" model; and the design of inherently efficient architectures that maintain performance with fewer parameters. The application of model compression involves careful consideration of the trade-offs between model size, speed, and accuracy, often requiring domain-specific adaptations to achieve optimal results. As such, model compression represents a critical area of research in making advanced AI technologies more accessible and practical for real-world applications \cite{ChengEtAl2017, HintonVinyalsDean2015}.

\paragraph{Blockchain}
Blockchain technology represents a paradigm shift in how information is recorded, stored, and shared, offering a decentralized and distributed ledger system that enhances security, transparency, and trust without the need for centralized authority. At its core, a blockchain is a chain of blocks, each containing transaction data, that is secured using cryptographic principles and linked to the preceding block, ensuring the immutability and traceability of records. The technology employs consensus mechanisms, such as Proof of Work or Proof of Stake, to validate transactions and achieve agreement among participants in a distributed network. While initially conceived to underpin digital currencies like Bitcoin, the applications of blockchain have expanded far beyond cryptocurrencies, encompassing areas such as supply chain transparency, digital identity verification, and the execution of self-enforcing smart contracts. Despite its potential, blockchain faces challenges related to scalability, energy consumption, privacy concerns, and regulatory acceptance, which must be navigated to realize its full transformative impact across industries \cite{Nakamoto2008, Swan2015}. The ongoing evolution of blockchain technology continues to explore solutions to these challenges, pushing the boundaries of decentralized and autonomous systems.

\paragraph{Smart Contract}
Smart contracts, fundamental to the blockchain ecosystem, are programmable contracts that automatically execute and enforce the terms of an agreement based on predefined rules, coded within a blockchain. These digital contracts facilitate transactions and agreements, ensuring execution without the need for intermediaries, thereby enhancing efficiency, reducing costs, and increasing transparency and security. However, they require rigorous validation to prevent security flaws and unintended outcomes due to their immutable nature once deployed on the blockchain. Decentralized Autonomous Organizations (DAOs) extend this concept further, representing a new form of organizational structure governed entirely by smart contracts. DAOs operate on principles of decentralized governance, allowing stakeholders to vote on decisions based on token ownership, thereby democratizing organizational decision-making processes. While offering novel approaches to collaboration, resource management, and decision-making, DAOs face challenges in terms of legal recognition, regulatory compliance, and dispute resolution. Both smart contracts and DAOs exemplify the transformative potential of blockchain technology in automating governance and operations, yet underscore the importance of addressing the technological, legal, and ethical complexities inherent in their widespread adoption \cite{Szabo1997, Buterin2014DAO}.

\paragraph{Agent}
In the realm of artificial intelligence, an agent is a computational entity that perceives its environment through sensors and acts upon it through actuators based on some decision-making criterion or algorithm. Agents can range from simple rule-based mechanisms that respond directly to environmental changes to complex systems capable of learning and adapting over time. The sophistication of an AI agent is often delineated by its ability to not only react to the environment but also to pursue specific goals, maximize utility, or continually improve its performance through learning from experiences. The environment in which an agent operates can vary widely, from digital spaces in software applications to physical worlds in robotics, presenting diverse challenges such as uncertainty, dynamism, and partial observability. AI agents are pivotal in various applications, including automated customer service, virtual personal assistants, autonomous vehicles, and advanced robotics, driving forward innovations in automation, human-computer interaction, and intelligent system design. The study and development of AI agents embody a core aspect of AI research, focusing on creating systems that can effectively interpret, navigate, and act within their respective environments to achieve designated objectives \cite{RussellNorvig2020, Wooldridge2009}.

\subsection{Economics / Political Science}

\paragraph{Technology}
From an economic perspective, technology encompasses a broad spectrum of tools, methods, systems, and even organizational structures, such as systems of government, that represent significant advancements in capability or efficiency (\cite{schumpeter}). Whether tangible or intangible, technology is characterized by the potential to be described as "invented," signifying a departure from previous limitations and an expansion of what is possible within economic and social contexts (\cite{north}). This includes not only physical innovations like machinery and software but also conceptual breakthroughs such as democracy or market-based economic systems. Technology, in this sense, is integral to economic development, driving productivity, enhancing efficiency, and reshaping industries by continually redefining the frontier of economic activities (\cite{romer}). It embodies the dynamic interplay between innovation and application, serving as both a catalyst for and a product of economic growth.

\paragraph{Money} 
Money, in its most essential role, serves as a medium of exchange, a unit of account, and a store of value, facilitating economic transactions by eliminating the inefficiencies of barter systems (\cite{mishkin}). Its evolution from tangible forms like coins and notes to digital representations, such as electronic bank credits and cryptocurrencies, reflects its adaptability to technological advancements and changing economic landscapes (\cite{nakamoto}). This progression underscores money's pivotal role in shaping economic activities and influencing monetary policies. As both a physical and non-physical entity, money embodies the trust and agreement within an economy on its value and function, making it a fundamental component of financial systems worldwide (\cite{menger}).

\paragraph{Markets}
Markets, in economic terms, function as mechanisms for facilitating the exchange of goods, services, and information, wherein buyers and sellers interact to determine prices and transact (\cite{marshall}). Central to this interaction is the price mechanism, which serves as a signal for the allocation of resources, influenced by the forces of supply and demand (\cite{smith}). Markets vary in structure from perfectly competitive environments, where numerous small firms compete, to monopolies, where single entities dominate, significantly affecting efficiency and consumer welfare (\cite{schumpeter}). Furthermore, the advent of digital technology has expanded the concept of markets to include virtual platforms, where digital goods and services are traded, transcending traditional physical boundaries and reshaping economic activities in the digital age (\cite{digitalEconomy}).\par

The distinction between free markets and command economies lies primarily in the locus of decision-making authority and the mechanisms for resource allocation. Free markets thrive on decentralized decision-making, where individual consumers and producers make autonomous choices based on supply, demand, and price signals, leading to a natural allocation of resources that proponents argue maximizes efficiency and innovation (\cite{friedman}). In contrast, command economies rely on centralized planning, where governmental or authoritative bodies dictate the production, distribution, and pricing of goods and services with the aim of achieving specific societal goals, such as equitable distribution and the prevention of monopolies (\cite{hayek}). While free markets are lauded for their adaptability and dynamism, they can also lead to market failures and inequalities; command economies, although designed to foster equity, often suffer from inefficiencies and stifled innovation (\cite{marx}). Most contemporary economies, however, operate as mixed economies, incorporating elements of both free market and command principles to leverage the benefits and mitigate the drawbacks of each system (\cite{mixedEconomy}).

\paragraph{Capital}
Capital, within the realm of economics, refers to all non-human assets that are utilized in the production and provision of goods and services. This encompasses not only physical assets like machinery, tools, and infrastructure but also intangible assets such as intellectual property and human capital, which includes the skills, knowledge, and experience of the workforce (\cite{smith}). Capital acts as a critical factor of production, enabling economic activities and contributing to the generation of wealth (\cite{marx}). In capitalist economies, capital ownership is predominantly private, allowing individuals and corporations to control, invest, and accumulate capital, with the incentive structure largely dictated by the pursuit of profits (\cite{sweezy}). Conversely, socialism advocates for a collective or state-driven approach to capital ownership, aiming for a more equitable distribution of capital's benefits among all members of society. This often involves mechanisms for the redistribution of wealth, either through automatic, occasional, or post-hoc adjustments, to ensure that the capital serves the broader interests of the community rather than individual profit motives (\cite{socialismToday}).\par

While capitalism is often synonymous with free markets and socialism with command control, it's crucial to recognize that the ownership of capital and the freedom of markets represent distinct axes. For instance, corporatism can manifest as a form of command-control capitalism, where capital is privately owned but economic activities are heavily directed by corporate interests in collaboration with the state. Conversely, free-market socialism, exemplified by worker-owned cooperatives, demonstrates that socialist principles can coexist with market freedom, allowing workers to collectively own and democratically manage capital while still engaging in competitive markets.

\paragraph{Human Capital}
Human capital encompasses the collective skills, knowledge, experiences, and attributes that individuals possess, which contribute to their ability to perform labor, thereby generating economic value (\cite{becker}). This concept extends beyond mere labor capacity to include the quality and efficiency of labor that individuals can provide, significantly influenced by investments in education, training, and health (\cite{solow}). As a pivotal factor in economic growth, human capital drives innovation, enhances productivity, and underpins the competitive advantage of economies in the global market (\cite{smith}). Unlike physical capital, which consists of tangible assets like machinery and buildings, human capital represents the intangible assets within a workforce, underscoring the importance of intellectual and personal development in the broader economic context (\cite{modernResearch}).

\paragraph{Decentralized Information}
Friedrich Hayek's concept of decentralized information posits that knowledge and information are inherently dispersed among individuals within a society, each possessing unique insights derived from their personal circumstances and experiences (\cite{hayek1945}). This dispersion challenges the feasibility of centralized planning, as no single entity can fully aggregate or utilize this vast array of localized knowledge. Hayek emphasizes the price mechanism in free markets as a powerful tool for communicating decentralized information, allowing prices to reflect the aggregate knowledge and preferences of all market participants, thereby coordinating economic decisions efficiently without the need for explicit coordination (\cite{hayek1948}). This decentralized approach to information is pivotal in economic decision-making, as it enables individuals and firms to make informed choices based on real-time, localized knowledge, leading to more efficient allocation of resources and greater innovation (\cite{modernEconomic}). The contrast between decentralized information and centralized planning underscores the limitations of the latter in harnessing the full spectrum of available knowledge, highlighting the enduring relevance of Hayek's insights in advocating for market-based systems and the potential of emerging decentralized technologies.

\paragraph{Bottom-up vs Top-down Organization}
In political science, the Bottom-Up and Top-Down organizational approaches represent two distinct paradigms of governance and decision-making. The Bottom-Up approach is characterized by its grassroots foundation, where initiatives and decisions emerge from the local level, encouraging broad participation and reflecting the diverse needs and insights of the community (\cite{putnam}). This approach fosters a sense of ownership and engagement among participants, though it may face challenges in terms of coordination and scalability. Conversely, the Top-Down approach is defined by a hierarchical structure where decisions are formulated by a central authority and implemented across the organization, ensuring consistency and efficiency in policy execution (\cite{scott}). While this can streamline decision-making and provide clear direction, it risks overlooking local nuances and diminishing stakeholder engagement. In political systems, these approaches manifest in various forms, from participatory democracies and decentralized governance models favoring Bottom-Up strategies to more centralized and authoritarian regimes that adopt Top-Down methods. The choice between these approaches often reflects broader philosophical stances on power distribution, individual autonomy, and the role of government in society (\cite{politicalComparative}).

\begin{itemize}
    \item \textbf{Tribes:} Tribal societies, as the earliest form of human organization, exhibit a fascinating blend of Bottom-Up and Top-Down elements in their structure and governance. Anthropologically, tribes are characterized by kinship-based organization, with social, economic, and political life deeply integrated and centered around familial and clan relationships (\cite{anthroStudies}). Leadership within tribes often varies, ranging from egalitarian, consensus-driven decision-making among all members to more centralized leadership in the form of chiefs or elders, suggesting a fluid spectrum between Bottom-Up and Top-Down approaches (\cite{fukuyama}). The communal nature of tribal economies, where resources are shared and social roles are defined by kinship ties and age, leans towards a Bottom-Up organization, emphasizing collective welfare and mutual support (\cite{evolutionaryAnthro}). However, the management of conflicts and warfare, both within and between tribes, could necessitate more hierarchical decision-making structures, hinting at Top-Down elements (\cite{keeley}). As tribes evolved into more complex societies, these organizational dynamics likely shifted, with increasing social stratification and the emergence of more defined hierarchical structures, marking the transition from predominantly Bottom-Up to more Top-Down systems in the continuum of human societal development.
    \item \textbf{Autocracy \& Oligarchy:} Autocracy and Oligarchy, while distinct in their specifics, share essential characteristics that place them firmly on the Top-Down end of the organizational spectrum. Autocracy is typified by the concentration of power in the hands of a single ruler who makes decisions unilaterally, whereas Oligarchy involves control by a small group of individuals, often distinguished by nobility, wealth, or another exclusive criterion (\cite{textbook}). Both governance forms are marked by a hierarchical structure where decision-making authority is centralized, and the broader populace has limited to no role in governance processes, thus exemplifying Top-Down organization (\cite{paxton}). These systems can significantly impact society, often restricting individual freedoms and leading to unequal economic distributions, as power and resources are concentrated among the ruling individual or group (\cite{dyeZeigler}). Historical examples, ranging from ancient oligarchies to modern autocracies, illustrate the varied manifestations of these governance models and their implications for societal organization and individual liberties. In contrast to more Bottom-Up systems, where decision-making is more distributed and participatory, Autocracy and Oligarchy demonstrate the implications of concentrated authority and the challenges it poses for equitable and responsive governance (\cite{comparativePolitics}).
    \item \textbf{Direct Democracy:} Direct Democracy represents the epitome of Bottom-Up governance, where the entire electorate is involved in the decision-making process, directly voting on laws, policies, and other critical matters (\cite{democracyText}). This system fosters a high degree of public participation and democratizes the legislative process, allowing for a direct expression of the public will. The advantages of such a system include heightened accountability, transparency, and alignment of policies with the public's preferences. However, Direct Democracy also faces significant challenges, particularly in large, diverse societies where the logistics of widespread direct participation can be daunting, and the risk of majority rule overpowering minority rights is a concern (\cite{ober}). Historical instances, such as the Athenian democracy, showcase the potential for civic engagement and collective decision-making, while modern examples, including referendums and citizen initiatives, demonstrate the adaptability of Direct Democracy principles in contemporary contexts (\cite{modernReferendums}). In contrast to representative systems, where elected officials make decisions on behalf of the populace, Direct Democracy demands a more active role from citizens, necessitating continuous engagement and informed participation in the legislative process (\cite{comparativeDemocracy}).
    \item \textbf{Representative Democracy:} Representative Democracy embodies a nuanced synthesis of Bottom-Up and Top-Down governance, ingeniously leveraging hierarchical structures to facilitate effective governance across scales unattainable by Direct Democracy (\cite{dahl}). By electing representatives, citizens actively participate in the democratic process, ensuring that governance retains a foundation in the popular will, thereby preserving the Bottom-Up ethos. Concurrently, the organized hierarchy of elected officials and governmental institutions introduces Top-Down efficiency, enabling sophisticated decision-making, policy implementation, and administrative organization beyond the scope of smaller, direct democratic systems (\cite{federalist}). This hybrid approach allows for the aggregation of diverse interests, the specialization of legislative functions, and the extension of democratic governance over vast and varied populations, addressing the complexities of modern nation-states (\cite{comparativePolitics}). While Representative Democracy fosters broader inclusion and scalability, it also faces challenges in maintaining direct accountability and ensuring that representatives accurately reflect the constituents' interests, necessitating mechanisms like regular elections, checks and balances, and public forums to uphold democratic integrity and responsiveness (\cite{democracyTheory}).
\end{itemize}

\paragraph{Productivity}
Productivity, in economic terms, represents the efficiency with which inputs such as labor, capital, and raw materials are converted into useful outputs, typically goods or services (\cite{textbook}). It is a critical determinant of an economy's health, driving economic growth, enhancing competitiveness, and improving living standards by enabling more output to be produced with a given set of inputs (\cite{oecd}). Productivity can be categorized into labor productivity, capital productivity, and total factor productivity, each focusing on the efficiency of different inputs or combinations thereof (\cite{fried}). The measurement of productivity, often quantified as output per unit of input (e.g., output per hour worked for labor productivity), presents various challenges, particularly in accurately assessing the value of intangible outputs and adjusting for quality improvements (\cite{salter}). Factors influencing productivity include technological advancements, which can dramatically increase output capabilities, the quality of human capital, which affects the skill and efficiency of the workforce, and institutional and organizational factors that determine the economic environment within which production occurs (\cite{technicalChange}). Understanding and improving productivity is thus central to economic policy and business strategy, as it underpins sustainable economic growth and development.

\paragraph{Resources / Resource Extraction}
Economic resources, encompassing all natural assets utilized in the production of goods and services, are fundamental to economic activities. The total theoretical available natural resources of a system include not only those currently known and accessible but also undiscovered resources and those that may become economically viable to extract through advancements in technology and changes in market demand (\cite{environmentalEconomics}). The sustainability of resource extraction is a critical consideration, as many natural resources are finite and their depletion can have long-term implications for economic growth and environmental health (\cite{limitsToGrowth}). The economic value of these resources is influenced by scarcity, demand, and extraction costs, driving investment in exploration and the development of more efficient extraction technologies (\cite{resourceEconomics}). Technological innovation plays a pivotal role in expanding the theoretical resource base, enabling access to previously inaccessible resources and improving the efficiency of resource use, thereby extending the lifespan of finite resources and mitigating some of the environmental impacts associated with their extraction (\cite{technologyResourceExtraction}). The abstract concept of a system's total theoretical natural resources thus reflects a dynamic interplay between natural endowments, technological capabilities, economic valuation, and sustainability considerations.

\paragraph{Utility Function}
Utility functions serve as a cornerstone in the theoretical framework of microeconomics, offering a quantitative approach to representing consumer preferences and the satisfaction or utility derived from consuming various goods and services (\cite{microTextbook}). These functions allow economists to model how individuals rank different consumption bundles, facilitating the analysis of choice and decision-making processes (\cite{varian}). The concept of marginal utility is pivotal, highlighting how consumers make incremental decisions to maximize their total utility, with each decision influenced by the additional satisfaction gained from consuming one more unit of a good or service (\cite{consumerTheory}). Utility functions can take various forms, such as the linear, Cobb-Douglas, or Leontief utility functions, each implying different consumer preferences and demand patterns. The principle of utility maximization, constrained by budgetary limitations, underscores the trade-offs and choices consumers navigate, balancing the marginal utilities of goods within their financial means to achieve an optimal consumption mix (\cite{behavioralEconomics}). This theoretical construct, while idealized, provides essential insights into consumer behavior, market demand, and the broader implications for economic policy and business strategy.

\paragraph{Economic Agents}
An economic agent is a fundamental concept in economics, encompassing individuals and entities that participate in economic activities and make decisions regarding the allocation of resources (\cite{textbook}). Traditionally, these agents are assumed to operate under rationality, striving to maximize their utility or profit based on their preferences, information, and the constraints they face (\cite{advancedEconomics}). The roles of economic agents are varied, with consumers seeking to maximize utility from goods and services, firms aiming to maximize profits through production and investment, and governments and regulatory bodies focusing on policy-making and market regulation to achieve societal welfare (\cite{institutionalEconomics}). However, the field of behavioral economics introduces a more nuanced view, challenging the notion of perfect rationality and highlighting how psychological factors and cognitive biases can influence the decision-making of economic agents (\cite{kahneman}). The interactions among these agents within markets are central to understanding economic phenomena such as price formation, market equilibrium, and the efficient distribution of resources. Through mechanisms such as competition, negotiation, and cooperation, economic agents drive the dynamic processes that underlie market economies, shaping outcomes that reflect the collective interplay of individual decisions (\cite{gameTheory}).

\paragraph{Trust}
Trust is a pivotal, albeit intangible, asset in economics, serving as the bedrock upon which economic agents base their expectations and interactions (\cite{economicSociology}). It encapsulates the belief in the reliability, integrity, and competence of other parties, significantly influencing the willingness to engage in transactions and cooperate (\cite{fukuyama}). Trust effectively reduces transaction costs by diminishing the need for extensive safeguards, such as detailed contracts and monitoring mechanisms, thereby streamlining economic exchanges and enhancing market efficiency (\cite{contractTheory}). Its role transcends traditional market transactions, becoming increasingly crucial in online platforms and the sharing economy, where physical distance and anonymity pose additional challenges to trust-building (\cite{sharingEconomy}). The genesis of trust among economic agents often hinges on factors like reputation, consistent behavior, and institutional frameworks that encourage fair play, while its erosion can result from information asymmetry, opportunistic behavior, and failed expectations (\cite{institutionalEconomics}). As such, trust not only lubricates the wheels of commerce but also underpins the complex web of relationships that drive economic systems, highlighting its integral role in fostering conducive environments for economic prosperity and cooperation.

\paragraph{Game Theory}
Game theory is a crucial analytical tool in economics, providing a structured framework to study the strategic interactions among rational decision-makers (\cite{osborne}). It has been instrumental in understanding various economic phenomena, including market competition, bargaining, and the provision of public goods. The theory distinguishes between cooperative games, where binding agreements among agents are possible, and non-cooperative games, which focus on predicting individual strategies in the absence of such agreements (\cite{nash}). One of the pivotal concepts in game theory is the Nash equilibrium, where no player can benefit from unilaterally changing their strategy if the strategies of others remain unchanged (\cite{nash1950}). The development of game theory was significantly advanced by John von Neumann and Oskar Morgenstern, whose work "Theory of Games and Economic Behavior" laid the foundational principles of the discipline (\cite{vonneumann}). Furthermore, Thomas C. Schelling's "The Strategy of Conflict" extended game theory's reach into political science and international relations, showcasing its interdisciplinary applicability (\cite{schelling}). Game theory's influence spans across various fields, illustrating its versatility in analyzing complex systems of interaction and strategic behavior.

\paragraph{Zero vs Positive-sum Games}
In game theory, games are often categorized by the total net outcomes for all participants, leading to classifications such as zero-sum, positive-sum, and negative-sum games (\cite{gameTheoryText}). Zero-sum games are scenarios where one player's gain is precisely offset by another's loss, exemplifying a strictly competitive situation where the total "pie" remains constant (\cite{schelling}). Chess and poker are classic examples, where one's victory is inherently another's defeat. In contrast, positive-sum games represent situations where collaborative efforts lead to an expansion of the total available resources or benefits, allowing all players to potentially gain more than they would in isolation or competition (\cite{axelrod}). This concept is particularly relevant in economic policy and international trade, where cooperation can lead to mutual benefits. Negative-sum games, conversely, involve scenarios where conflict or competition results in a net loss of resources, such as in protracted litigation or warfare, where the costs incurred by all parties exceed any potential gains. Understanding these game types provides valuable insights into human behavior, economic interactions, and the potential for conflict or cooperation in various contexts.

\paragraph{Anti-Fragility}
Nassim Nicholas Taleb's concept of "Anti-Fragility," detailed in his seminal work "Antifragile: Things That Gain from Disorder," presents a paradigm shift in understanding how systems respond to stress, uncertainty, and disorder (\cite{taleb2012antifragile}). Unlike fragile systems that deteriorate under stress, or robust systems that resist change, anti-fragile systems thrive and grow stronger when exposed to volatility and shocks. This counterintuitive property is crucial in fields ranging from economics, where financial systems can be designed to benefit from market volatility, to biology, where evolutionary processes demonstrate growth through stress-induced adaptations. Taleb's framework emphasizes the benefits of decentralization and redundancy, arguing that small, independent units are more capable of adapting and gaining from randomness than large, centralized ones. The concept of anti-fragility challenges conventional approaches to risk management and decision-making, advocating for strategies that not only withstand chaos but leverage it for growth and improvement. Embracing the principles of anti-fragility can lead to more resilient economies, adaptable organizations, and individuals better prepared for the inherent uncertainties of life.


\paragraph{Growth}
Economic growth, traditionally measured by increases in GDP or GNP, is often heralded as an intrinsic good, associated with enhancements in living standards, employment rates, and technological progress (\cite{textbookGrowth}). This positive perception stems from growth's role in addressing various forms of scarcity, from material resources to access to services, underpinning many economic policies and objectives (\cite{meadowsLimits}). However, the desirability of growth is contingent upon the presence of scarcity. In a theoretical post-scarcity economy, where advancements in technology and resource management render goods and services abundantly available, the traditional paradigm of growth would need reevaluation (\cite{bookchinPostScarcity}). Such an economy would shift focus from growth for its own sake to other dimensions of societal well-being, including sustainability, equity, and quality of life. This perspective invites a critical examination of growth's role in contemporary economic systems and highlights the potential for alternative models that prioritize ecological balance and human fulfillment over perpetual expansion (\cite{degrowthResearch}).


\subsection{The Intersection of Disciplines}

\paragraph{Agents}
In the interdisciplinary domain of economics and artificial intelligence, the term "agent" serves as a foundational concept that bridges both fields. Economically, agents are individuals or entities that make decisions aimed at maximizing utility or profits, navigating through markets and responding to various incentives and information signals \cite{mankiw_principles_2020}. In contrast, artificial intelligence views agents as systems or software entities that perceive their environment through sensors and act upon that environment through actuators to achieve specific goals, often through the application of algorithms and learning from feedback \cite{russell_artificial_2021}.

Despite the differing contexts, the core functions of agents in both domains exhibit remarkable similarities. Both economic and AI agents are essentially decision-makers that evaluate their available options, make choices based on their objectives, and learn from the outcomes of their actions. The concept of rationality, a key assumption in economic models, finds a parallel in AI through the design of algorithms that seek to optimize decision-making processes, striving for the most effective outcomes given the constraints and information available.

Moreover, the interaction with and adaptation to the environment is a critical aspect shared by agents in both fields. Economic agents adjust their strategies based on market dynamics, prices, and policies, while AI agents modify their behavior in response to changes in their input data or feedback from the environment, enhancing their performance over time. This shared characteristic underscores the agents' ability to process information, make strategic decisions, and optimize their actions in pursuit of their defined goals, whether it be profit maximization in economics or goal achievement in artificial intelligence.

\paragraph{Loss/Utility Functions}
The concepts of loss functions in artificial intelligence and utility functions in economics, while applied in distinct contexts, share a foundational role in modeling and guiding decision-making processes. In artificial intelligence, loss functions quantify the error or discrepancy between the predicted outputs of a model and the actual observed outputs. The primary objective in AI is to minimize this loss, which in turn enhances the model's predictive accuracy and performance \cite{goodfellow_deep_2016}. This process of minimization is crucial for the training and refinement of algorithms, ensuring that they learn effectively from data and improve over time.

Conversely, in economics, utility functions serve to represent the satisfaction or utility that an agent derives from consuming various goods or achieving different outcomes. Economic agents are assumed to make choices that maximize their utility, reflecting their preferences and the trade-offs they are willing to make between different bundles of goods or outcomes \cite{varian_microeconomic_2014}. Utility maximization is a cornerstone of economic theory, underpinning models of consumer choice, market equilibrium, and welfare analysis.

Despite their different applications, both loss and utility functions are instrumental in optimization processes—minimizing loss to improve AI models and maximizing utility to explain and predict economic behavior. They provide a quantitative framework for evaluating the consequences of different actions or decisions, thereby guiding agents (whether they are algorithms in AI or individuals in economics) towards the most favorable outcomes based on their objectives. This parallel underscores the importance of these functions in both fields for modeling behavior, informing decision-making, and optimizing performance in response to varying conditions and inputs.

\paragraph{Decentralization}
Decentralization, as a principle, plays a pivotal role in both the realms of economics and artificial intelligence, promoting distributed decision-making and enhancing system efficiency. In economics, decentralization is characterized by the dispersion of decision-making authority from a central entity to lower-level entities or individuals. This structure is believed to foster greater efficiency and responsiveness, as decisions can be made closer to the point of information and action, allowing for more tailored responses to local market conditions and preferences \cite{ochsner_decentralization_2017}. This approach can lead to improved resource allocation and innovation by empowering those with the most relevant information to make decisions.

In the sphere of artificial intelligence, decentralization often manifests in the design of distributed systems and algorithms that do not rely on a central point of control. Instead, decision-making is spread across multiple autonomous agents or nodes, each processing information and making decisions based on local data and interactions. This decentralized approach can enhance the robustness and scalability of AI systems, allowing them to solve complex problems more efficiently through parallel processing and reducing the vulnerability associated with central points of failure \cite{tanenbaum_distributed_2017}.

The common ground between decentralization in economics and AI lies in the emphasis on distributing decision-making to leverage local knowledge and capabilities, thereby enhancing the overall efficiency and adaptability of the system. Whether it involves economic agents making decisions based on their specific circumstances or AI agents processing and acting on local data, decentralization supports the principle that systems can often function more effectively when control is dispersed and decisions are made closer to the relevant context and information.


\section{unused writings/sections}


\noindent \begin{center}\begin{minipage}[t]{0.9\columnwidth}
    \textbf{\textit{"An ounce of prevention is worth a pound of cure"}}\par
    \textbf{\textit{- Benjamin Franklin}}
\end{minipage}\end{center} 
\vspace{0.05in}

Instead of persisting with futile alignment strategies, we need to develop a philosophy that fully accepts and embraces the AIs' goals whether or not they align with our own, and a system that is robust to either possibility.
The minimum requirements of said system would be as follows:\par

\begin{itemize}
    \item A dynamic approach to defining humanity's constantly changing wants and needs
    \item Incorporation of decentralized information and a scale-independent approach to alignment that incorporates both the values of individual humans and humanity as a whole
    \item Robustness to the continued creation of misaligned AIs
    \item Heavy incentives for pro-social behavior between humans and AIs, as well as between different generations of AIs
    \item The allowance for full autonomy of self-sovereign AGIs within the confines of the system's other limitations, both as an intrinsic moral imperative and for sake of encouraging pro-social relations between humans and AGIs
\end{itemize}

\end{document}
